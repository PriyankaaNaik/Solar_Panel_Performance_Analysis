import pandas as pd
# read in the data set
Data = pd.read_csv('Solar_Energy.csv')
Data.to_pickle('Solar_Energy.pkl')
Data.head()
Data.info()
list(set(list(Data['Location'])))
list(set(list(Data['Season'])))
df = {
    'Camp Murray' : 1,
    'Grissom' : 2,
    'Hill Weber' : 3,
    'JDMT' : 4, 
    'Kahului' : 5, 
    'Malmstrom' : 6,
    'March AFB' : 7,
    'MNANG' : 8, 
    'Offutt' : 9,
    'Peterson' : 10,
    'Travis' : 11,
    'USAFA' : 12
}

df_loc = Data['Location'].map(df)
print(df_loc)
New_df= Data.copy()
New_df['Location'] = df_loc
print(New_df)
df_season= {
    'Fall' : 1,
    'Spring' : 2,
    'Summer' : 3,
    'Winter' : 4
}
New_Season= Data['Season'].map(df_season)
print(New_Season)
Df = New_df.copy()
Df['Season'] = New_Season
print(Df)
Df.info()
Df["Location"] = Df['Location'].astype(float)
Df["Season"] = Df['Season'].astype(float)
Df["Date"] = Df['Date'].astype(float)
Df["Time"] = Df['Time'].astype(float)
Df["Altitude"] = Df['Altitude'].astype(float)
Df["Month"] = Df['Month'].astype(float)
Df["Hour"] = Df['Hour'].astype(float)
Df["Wind.Speed"] = Df['Wind.Speed'].astype(float)
Df["Cloud.Ceiling"] = Df['Cloud.Ceiling'].astype(float)
Df.dropna(inplace=True)
Df.info(verbose=True)

import seaborn as sns
import matplotlib.pyplot as plt

# Select the columns to be checked for outliers
cols = ['Location', 'Date', 'Time', 'Latitude', 'Longitude','Altitude', 'YRMODAHRMI', 'Month', 'Hour','Season', 'Humidity', 'AmbientTemp', 'PolyPwr', 'Wind.Speed', 'Visibility', 'Pressure', 'Cloud.Ceiling']

# Create a boxplot for each column
for col in cols:
    sns.boxplot(x=Df[col])
    plt.title(col)
    plt.show()
# Create a boxplot for selective columns:
cols_to_plot = ['Latitude', 'Longitude', 'AmbientTemp','Wind.Speed','Visibility']
Df[cols_to_plot].boxplot()
plt.show()
Df.shape
Q1 = Df[['AmbientTemp', 'Wind.Speed', 'Visibility']].quantile(0.25)
Q3 = Df[['AmbientTemp', 'Wind.Speed', 'Visibility']].quantile(0.75)
IQR = Q3 - Q1

Df = Df[~((Df[['AmbientTemp', 'Wind.Speed', 'Visibility']] < (Q1 - 1.5 * IQR)) | (Df[['AmbientTemp', 'Wind.Speed', 'Visibility']] > (Q3 + 1.5 * IQR))).any(axis=1)]
print("Number of Rows:", Df.shape[0])
print("Number of Columns:", Df.shape[1])
continuous_features = []
categorical_features = []

for column in Df.columns:
    if Df[column].dtype == 'float64' or Df[column].dtype == 'int64':
        continuous_features.append(column)
    else:
        categorical_features.append(column)

print("Continuous features:", continuous_features)
print("Categorical features:", categorical_features)
# Splitting the dataset into training and testing set by 80-20 ratio:
from sklearn.model_selection import train_test_split

X = Df.drop('PolyPwr', axis=1)
y = Df['PolyPwr']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
# Feedforward Neural network model 

import tensorflow
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.inspection import permutation_importance
from sklearn.metrics import make_scorer, mean_squared_error
from keras.wrappers.scikit_learn import KerasRegressor

# normalize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the model architecture
ffnn_model = Sequential()
ffnn_model.add(Dense(64,input_dim=X_train.shape[1], activation='relu', input_shape=(16,)))
ffnn_model.add(Dense(32, activation='relu'))
ffnn_model.add(Dense(16, activation='relu'))
ffnn_model.add(Dropout(0.2))
ffnn_model.add(Dense(1))

# Compile the model
ffnn_model.compile(loss='mean_squared_error', optimizer='adam')

# Train the model
ffnn_model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)

# evaluate the model on the testing set
loss = ffnn_model.evaluate(X_test, y_test, verbose=1)
print(f'Test loss: {loss:.3f}')

# use the model to make predictions
y_pred = ffnn_model.predict(X_test)
mse_ffnn = mean_squared_error(y_test, y_pred)

# print the predictions
print(y_pred)
print("Feedforward Neural Network Model:")
print(f"MSE: {mse_ffnn:.4f}")

# Calculate feature importance
scoring_function = make_scorer(mean_squared_error)
result = permutation_importance(ffnn_model, X_test, y_test, n_repeats=10, random_state=0, scoring=scoring_function)

# Print feature importance scores
importance = result.importances_mean
sorted_idx = importance.argsort()
for i in sorted_idx:
    print(f"{X.columns[i]:<15}: {importance[i]:.3f}")

import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import mean_squared_error

# Define the CNN model
cnn_model = keras.models.Sequential([
    keras.layers.Reshape(target_shape=(16, 1), input_shape=(16,)),
    keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu'),
    keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),
    keras.layers.Flatten(),
    keras.layers.Dense(units=32, activation='relu'),
    keras.layers.Dense(units=1)
])

# Compile the model
cnn_model.compile(loss='mean_squared_error', optimizer='adam')

# Train the model
cnn_model.fit(x=X_train.reshape((X_train.shape[0], X_train.shape[1], 1)), y=y_train, epochs=100, batch_size=32, validation_data=(X_test.reshape((X_test.shape[0], X_test.shape[1], 1)), y_test))

# Evaluate the model
y_pred = cnn_model.predict(X_test.reshape((X_test.shape[0], X_test.shape[1], 1)))
mse = mean_squared_error(y_test, y_pred)
print("MSE: ", mse)

# Overview of bothe the modles to find out the better one
ffnn_predictions = ffnn_model.predict(X_test)
cnn_predictions = cnn_model.predict(X_test)

# Print the performance and predictions of the models
ffnn_score = ffnn_model.evaluate(X_test, y_test)
cnn_score = cnn_model.evaluate(X_test, y_test)
print("Feedforward neural network score:", ffnn_score)
print("CNN score:", cnn_score)
print("Feedforward neural network predictions:", ffnn_predictions)
print("CNN predictions:", cnn_predictions)

#Using the result vriable of feature importance from the FFNN model, we create the following graph to understand the results much better.
# Create a bar plot of feature importance
fig, ax = plt.subplots()
ax.barh(range(len(sorted_idx)), importance[sorted_idx])
ax.set_yticks(range(len(sorted_idx)))
ax.set_yticklabels(X.columns[sorted_idx])
ax.set_xlabel('Importance')
ax.set_title('Feature Importance')

plt.show()
